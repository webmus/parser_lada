# Рекомендации по устранению дублей и ускорению публикации

## 1. Параллельный запуск action=news
В сценарии `action=news` отсутствует любая синхронизация. Процесс одновременно читает весь `list.dat`,
выполняет модули парсинга и только после завершения цикла перезаписывает файл, поэтому два параллельных
запуска обрабатывают одну и ту же запись как «Новый».【F:parsing-lada.xml†L4406-L4501】

**Что сделать**
- Добавить файловую блокировку (`flock`) или иной механизм эксклюзивного запуска по аналогии с `action=list`.
- При чтении очереди помечать элемент как «В работе» и сразу сохранять файл, чтобы второй процесс увидел
  изменённый статус.
- Оборачивать работу с `list.dat` в `flock` или перезаписать очередь на хранение в БД.

Это остановит конкурентное выполнение модулей и устранит повторный запуск рерайта/публикации для одной и той же новости.

## 2. Защита на уровне базы данных
Даже если очередь будет защищена от гонок, в `addPost()` остаётся окно между `SELECT` и `INSERT`, поэтому
два процесса успевают вставить два идентичных ряда с одинаковым `url`, если стартовали параллельно.【F:parsing-lada.xml†L4896-L5074】

**Что сделать**
- Создать уникальный индекс на поле `url` таблицы `{prefix}_post` и/или использовать `INSERT ... ON DUPLICATE KEY UPDATE`.
- Рассмотреть перевод проверки «существует ли запись» на `INSERT IGNORE` или `REPLACE` внутри транзакции.

Такой барьер исключит дубль даже при ошибке синхронизации в очереди.

## 3. Влияние расширенного логирования на время публикации
Каждый вызов `addLog()` пишет строку в файл с `LOCK_EX`, а `doGPT()` сохраняет полный JSON-ответ модели в лог.
Чем длиннее ответ, тем больше файловых операций и ожиданий блокировок при последовательной обработке нескольких
полей (full, short, title, meta).【F:parsing-lada.xml†L4561-L4634】【F:parsing-lada.xml†L4660-L4744】

**Что сделать**
- Оставить подробное логирование только на период диагностики (например, обрезать ответ до N символов или вынести
  отладку в отдельный канал).
- Проверить, не пишется ли одновременно `ROOT_DIR/../log.txt`, чтобы исключить контенцию нескольких файловых логов.

После устранения дублей время публикации сократится естественно, но уменьшение объёма логов дополнительно снизит задержки
на файловых операциях.

## 4. Дополнительные наблюдения
- `addToList()` тоже работает без блокировок и перезаписывает весь `list.dat`, поэтому при одновременном сборе ссылок из нескольких
  cron-задач возможны потери элементов. Стоит синхронизировать и этот участок.【F:parsing-lada.xml†L4561-L4593】
- Рассмотреть перенос очереди в таблицу БД — это упростит постановку статусов («Новый», «В работе», «Готово») и сделает транзакционные
  проверки естественными.

Внедрение указанных механизмов позволит убрать дубли публикаций и стабилизировать время обработки без изменений логики рерайта.
